{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1276,
     "status": "ok",
     "timestamp": 1620282355249,
     "user": {
      "displayName": "Ramesh Bhutka",
      "photoUrl": "https://lh3.googleusercontent.com/-jBSHGVJvh3M/AAAAAAAAAAI/AAAAAAAAchY/NveHJuhGTqU/s64/photo.jpg",
      "userId": "06756766942721289592"
     },
     "user_tz": -330
    },
    "id": "ipDaBFK9rxJw",
    "outputId": "3efd8273-b984-4da3-952a-8c9bcb9bcca1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME:- RAMESH BHUTKA\n",
      "SAP ID:- 5300419003\n"
     ]
    }
   ],
   "source": [
    "print(\"NAME:- RAMESH BHUTKA\")\n",
    "print(\"SAP ID:- 5300419003\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1234,
     "status": "ok",
     "timestamp": 1620282357199,
     "user": {
      "displayName": "Ramesh Bhutka",
      "photoUrl": "https://lh3.googleusercontent.com/-jBSHGVJvh3M/AAAAAAAAAAI/AAAAAAAAchY/NveHJuhGTqU/s64/photo.jpg",
      "userId": "06756766942721289592"
     },
     "user_tz": -330
    },
    "id": "07Y3--TuryPx",
    "outputId": "f18e7041-bb1a-46e7-c4f2-34040c3d418a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-06 06:26:00.254848\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "as-8wjT7nSxh"
   },
   "source": [
    "# practical-5-x-or-problem\n",
    "\n",
    "Use the \"Run\" button to execute the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 4100,
     "status": "ok",
     "timestamp": 1620282362960,
     "user": {
      "displayName": "Ramesh Bhutka",
      "photoUrl": "https://lh3.googleusercontent.com/-jBSHGVJvh3M/AAAAAAAAAAI/AAAAAAAAchY/NveHJuhGTqU/s64/photo.jpg",
      "userId": "06756766942721289592"
     },
     "user_tz": -330
    },
    "id": "hfJa36NNnSxi"
   },
   "outputs": [],
   "source": [
    "!pip install jovian --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 847,
     "status": "ok",
     "timestamp": 1620282364579,
     "user": {
      "displayName": "Ramesh Bhutka",
      "photoUrl": "https://lh3.googleusercontent.com/-jBSHGVJvh3M/AAAAAAAAAAI/AAAAAAAAchY/NveHJuhGTqU/s64/photo.jpg",
      "userId": "06756766942721289592"
     },
     "user_tz": -330
    },
    "id": "xfEyFRSdnSxk"
   },
   "outputs": [],
   "source": [
    "import jovian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "executionInfo": {
     "elapsed": 15857,
     "status": "ok",
     "timestamp": 1620282380245,
     "user": {
      "displayName": "Ramesh Bhutka",
      "photoUrl": "https://lh3.googleusercontent.com/-jBSHGVJvh3M/AAAAAAAAAAI/AAAAAAAAchY/NveHJuhGTqU/s64/photo.jpg",
      "userId": "06756766942721289592"
     },
     "user_tz": -330
    },
    "id": "vVD1xLjcnSxm",
    "outputId": "7ebee1a1-63fd-4a25-971c-0484a818d5a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Detected Colab notebook...\u001b[0m\n",
      "[jovian] Please enter your API key ( from https://jovian.ai/ ):\u001b[0m\n",
      "API KEY: ··········\n",
      "[jovian] Uploading colab notebook to Jovian...\u001b[0m\n",
      "[jovian] Capturing environment..\u001b[0m\n",
      "[jovian] Committed successfully! https://jovian.ai/rameshbhutka11/practical-5-x-or-problem\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'https://jovian.ai/rameshbhutka11/practical-5-x-or-problem'"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Execute this to save new versions of the notebook\n",
    "jovian.commit(project=\"practical-5-x-or-problem\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 3459,
     "status": "ok",
     "timestamp": 1620282389679,
     "user": {
      "displayName": "Ramesh Bhutka",
      "photoUrl": "https://lh3.googleusercontent.com/-jBSHGVJvh3M/AAAAAAAAAAI/AAAAAAAAchY/NveHJuhGTqU/s64/photo.jpg",
      "userId": "06756766942721289592"
     },
     "user_tz": -330
    },
    "id": "2HLqI5NonSxq"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 862,
     "status": "ok",
     "timestamp": 1620282391509,
     "user": {
      "displayName": "Ramesh Bhutka",
      "photoUrl": "https://lh3.googleusercontent.com/-jBSHGVJvh3M/AAAAAAAAAAI/AAAAAAAAchY/NveHJuhGTqU/s64/photo.jpg",
      "userId": "06756766942721289592"
     },
     "user_tz": -330
    },
    "id": "RKw-RINtotCu"
   },
   "outputs": [],
   "source": [
    "# creating dataset\n",
    "x = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y = np.array([0, 1, 1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 1358,
     "status": "ok",
     "timestamp": 1620282393622,
     "user": {
      "displayName": "Ramesh Bhutka",
      "photoUrl": "https://lh3.googleusercontent.com/-jBSHGVJvh3M/AAAAAAAAAAI/AAAAAAAAchY/NveHJuhGTqU/s64/photo.jpg",
      "userId": "06756766942721289592"
     },
     "user_tz": -330
    },
    "id": "rzZhPOx0ouue"
   },
   "outputs": [],
   "source": [
    "# callback to stop training when validation accuracy is 100%\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        try:\n",
    "            if logs.get('val_accuracy') == 1.0:\n",
    "                print(\"\\nReached 100% accuracy, stopping training\")\n",
    "                self.model.stop_training = True\n",
    "        except:\n",
    "            pass\n",
    "        return\n",
    "\n",
    "callbacks = myCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1136,
     "status": "ok",
     "timestamp": 1620282396077,
     "user": {
      "displayName": "Ramesh Bhutka",
      "photoUrl": "https://lh3.googleusercontent.com/-jBSHGVJvh3M/AAAAAAAAAAI/AAAAAAAAchY/NveHJuhGTqU/s64/photo.jpg",
      "userId": "06756766942721289592"
     },
     "user_tz": -330
    },
    "id": "PtT1MWv4owRN",
    "outputId": "0efb977c-c88d-4591-dcb1-40d101cc1d26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 12        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 23\n",
      "Trainable params: 23\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# creating tensorflow model\n",
    "model = tf.keras.models.Sequential([\n",
    "        # input layer\n",
    "        tf.keras.layers.Dense(2, input_shape = (2,), activation='relu'),\n",
    "        # hidden layer\n",
    "        tf.keras.layers.Dense(4, activation='relu'),\n",
    "        # output neuron\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid'),\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 776,
     "status": "ok",
     "timestamp": 1620282398003,
     "user": {
      "displayName": "Ramesh Bhutka",
      "photoUrl": "https://lh3.googleusercontent.com/-jBSHGVJvh3M/AAAAAAAAAAI/AAAAAAAAchY/NveHJuhGTqU/s64/photo.jpg",
      "userId": "06756766942721289592"
     },
     "user_tz": -330
    },
    "id": "LEf3R-LMoyed"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = 'rmsprop',\n",
    "    loss = 'binary_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27040,
     "status": "ok",
     "timestamp": 1620282429079,
     "user": {
      "displayName": "Ramesh Bhutka",
      "photoUrl": "https://lh3.googleusercontent.com/-jBSHGVJvh3M/AAAAAAAAAAI/AAAAAAAAchY/NveHJuhGTqU/s64/photo.jpg",
      "userId": "06756766942721289592"
     },
     "user_tz": -330
    },
    "id": "SXoa4saHo19c",
    "outputId": "ae43eb29-8345-44b6-d7e4-36a9679dba61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6960 - accuracy: 0.5000 - val_loss: 0.6939 - val_accuracy: 0.2500\n",
      "Epoch 2/5000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6939 - accuracy: 0.2500 - val_loss: 0.6938 - val_accuracy: 0.2500\n",
      "Epoch 3/5000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6938 - accuracy: 0.2500 - val_loss: 0.6936 - val_accuracy: 0.2500\n",
      "Epoch 4/5000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6936 - accuracy: 0.2500 - val_loss: 0.6935 - val_accuracy: 0.2500\n",
      "Epoch 5/5000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6935 - accuracy: 0.2500 - val_loss: 0.6935 - val_accuracy: 0.2500\n",
      "Epoch 6/5000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6935 - accuracy: 0.2500 - val_loss: 0.6934 - val_accuracy: 0.2500\n",
      "Epoch 7/5000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6934 - accuracy: 0.2500 - val_loss: 0.6933 - val_accuracy: 0.2500\n",
      "Epoch 8/5000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6933 - accuracy: 0.2500 - val_loss: 0.6933 - val_accuracy: 0.2500\n",
      "Epoch 9/5000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6933 - accuracy: 0.2500 - val_loss: 0.6932 - val_accuracy: 0.2500\n",
      "Epoch 10/5000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6932 - accuracy: 0.2500 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 11/5000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 12/5000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 13/5000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6930 - val_accuracy: 0.5000\n",
      "Epoch 14/5000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6930 - accuracy: 0.5000 - val_loss: 0.6930 - val_accuracy: 0.5000\n",
      "Epoch 15/5000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6930 - accuracy: 0.5000 - val_loss: 0.6929 - val_accuracy: 0.5000\n",
      "Epoch 16/5000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6929 - accuracy: 0.5000 - val_loss: 0.6929 - val_accuracy: 0.5000\n",
      "Epoch 17/5000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6929 - accuracy: 0.5000 - val_loss: 0.6929 - val_accuracy: 0.5000\n",
      "Epoch 18/5000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6929 - accuracy: 0.5000 - val_loss: 0.6928 - val_accuracy: 0.5000\n",
      "Epoch 19/5000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6928 - accuracy: 0.5000 - val_loss: 0.6928 - val_accuracy: 0.5000\n",
      "Epoch 20/5000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6928 - accuracy: 0.5000 - val_loss: 0.6928 - val_accuracy: 0.5000\n",
      "Epoch 21/5000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6928 - accuracy: 0.5000 - val_loss: 0.6927 - val_accuracy: 0.5000\n",
      "Epoch 22/5000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6927 - accuracy: 0.5000 - val_loss: 0.6927 - val_accuracy: 0.5000\n",
      "Epoch 23/5000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6927 - accuracy: 0.5000 - val_loss: 0.6927 - val_accuracy: 0.5000\n",
      "Epoch 24/5000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6927 - accuracy: 0.5000 - val_loss: 0.6927 - val_accuracy: 0.5000\n",
      "Epoch 25/5000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6927 - accuracy: 0.5000 - val_loss: 0.6926 - val_accuracy: 0.5000\n",
      "Epoch 26/5000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6926 - accuracy: 0.5000 - val_loss: 0.6926 - val_accuracy: 0.5000\n",
      "Epoch 27/5000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6926 - accuracy: 0.5000 - val_loss: 0.6926 - val_accuracy: 0.5000\n",
      "Epoch 28/5000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6926 - accuracy: 0.5000 - val_loss: 0.6925 - val_accuracy: 0.5000\n",
      "Epoch 29/5000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6925 - accuracy: 0.5000 - val_loss: 0.6925 - val_accuracy: 0.5000\n",
      "Epoch 30/5000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6925 - accuracy: 0.5000 - val_loss: 0.6925 - val_accuracy: 0.5000\n",
      "Epoch 31/5000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6925 - accuracy: 0.5000 - val_loss: 0.6925 - val_accuracy: 0.5000\n",
      "Epoch 32/5000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6925 - accuracy: 0.5000 - val_loss: 0.6924 - val_accuracy: 0.5000\n",
      "Epoch 33/5000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6924 - accuracy: 0.5000 - val_loss: 0.6924 - val_accuracy: 0.5000\n",
      "Epoch 34/5000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6924 - accuracy: 0.5000 - val_loss: 0.6924 - val_accuracy: 0.5000\n",
      "Epoch 35/5000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6924 - accuracy: 0.5000 - val_loss: 0.6923 - val_accuracy: 0.5000\n",
      "Epoch 36/5000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6923 - accuracy: 0.5000 - val_loss: 0.6923 - val_accuracy: 0.5000\n",
      "Epoch 37/5000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6923 - accuracy: 0.5000 - val_loss: 0.6923 - val_accuracy: 0.5000\n",
      "Epoch 38/5000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6923 - accuracy: 0.5000 - val_loss: 0.6922 - val_accuracy: 0.5000\n",
      "Epoch 39/5000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6922 - accuracy: 0.5000 - val_loss: 0.6922 - val_accuracy: 0.5000\n",
      "Epoch 40/5000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6922 - accuracy: 0.5000 - val_loss: 0.6922 - val_accuracy: 0.5000\n",
      "Epoch 41/5000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6922 - accuracy: 0.5000 - val_loss: 0.6921 - val_accuracy: 0.5000\n",
      "Epoch 42/5000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6921 - accuracy: 0.5000 - val_loss: 0.6921 - val_accuracy: 0.5000\n",
      "Epoch 43/5000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6921 - accuracy: 0.5000 - val_loss: 0.6921 - val_accuracy: 0.5000\n",
      "Epoch 44/5000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6921 - accuracy: 0.5000 - val_loss: 0.6920 - val_accuracy: 0.5000\n",
      "Epoch 45/5000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6920 - accuracy: 0.5000 - val_loss: 0.6920 - val_accuracy: 0.5000\n",
      "Epoch 46/5000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6920 - accuracy: 0.5000 - val_loss: 0.6920 - val_accuracy: 0.5000\n",
      "Epoch 47/5000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6920 - accuracy: 0.5000 - val_loss: 0.6919 - val_accuracy: 0.5000\n",
      "Epoch 48/5000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6919 - accuracy: 0.5000 - val_loss: 0.6919 - val_accuracy: 0.5000\n",
      "Epoch 49/5000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6919 - accuracy: 0.5000 - val_loss: 0.6918 - val_accuracy: 0.5000\n",
      "Epoch 50/5000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6918 - accuracy: 0.5000 - val_loss: 0.6918 - val_accuracy: 0.5000\n",
      "Epoch 51/5000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6918 - accuracy: 0.5000 - val_loss: 0.6917 - val_accuracy: 0.5000\n",
      "Epoch 52/5000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6917 - accuracy: 0.5000 - val_loss: 0.6917 - val_accuracy: 0.5000\n",
      "Epoch 53/5000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6917 - accuracy: 0.5000 - val_loss: 0.6917 - val_accuracy: 0.5000\n",
      "Epoch 54/5000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6917 - accuracy: 0.5000 - val_loss: 0.6916 - val_accuracy: 0.5000\n",
      "Epoch 55/5000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6916 - accuracy: 0.5000 - val_loss: 0.6916 - val_accuracy: 0.5000\n",
      "Epoch 56/5000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6916 - accuracy: 0.5000 - val_loss: 0.6915 - val_accuracy: 0.5000\n",
      "Epoch 57/5000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6915 - accuracy: 0.5000 - val_loss: 0.6915 - val_accuracy: 0.5000\n",
      "Epoch 58/5000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6915 - accuracy: 0.5000 - val_loss: 0.6914 - val_accuracy: 0.5000\n",
      "Epoch 59/5000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6914 - accuracy: 0.5000 - val_loss: 0.6914 - val_accuracy: 0.5000\n",
      "Epoch 60/5000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6914 - accuracy: 0.5000 - val_loss: 0.6913 - val_accuracy: 0.5000\n",
      "Epoch 61/5000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6913 - accuracy: 0.5000 - val_loss: 0.6913 - val_accuracy: 0.5000\n",
      "Epoch 62/5000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6913 - accuracy: 0.5000 - val_loss: 0.6913 - val_accuracy: 0.5000\n",
      "Epoch 63/5000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6913 - accuracy: 0.5000 - val_loss: 0.6912 - val_accuracy: 0.5000\n",
      "Epoch 64/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6912 - accuracy: 0.5000 - val_loss: 0.6912 - val_accuracy: 0.5000\n",
      "Epoch 65/5000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6912 - accuracy: 0.5000 - val_loss: 0.6911 - val_accuracy: 0.5000\n",
      "Epoch 66/5000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6911 - accuracy: 0.5000 - val_loss: 0.6911 - val_accuracy: 0.5000\n",
      "Epoch 67/5000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6911 - accuracy: 0.5000 - val_loss: 0.6910 - val_accuracy: 0.5000\n",
      "Epoch 68/5000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6910 - accuracy: 0.5000 - val_loss: 0.6910 - val_accuracy: 0.5000\n",
      "Epoch 69/5000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6910 - accuracy: 0.5000 - val_loss: 0.6909 - val_accuracy: 0.5000\n",
      "Epoch 70/5000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6909 - accuracy: 0.5000 - val_loss: 0.6908 - val_accuracy: 0.5000\n",
      "Epoch 71/5000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6908 - accuracy: 0.5000 - val_loss: 0.6908 - val_accuracy: 0.5000\n",
      "Epoch 72/5000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6908 - accuracy: 0.5000 - val_loss: 0.6907 - val_accuracy: 0.5000\n",
      "Epoch 73/5000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6907 - accuracy: 0.5000 - val_loss: 0.6907 - val_accuracy: 0.5000\n",
      "Epoch 74/5000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6907 - accuracy: 0.5000 - val_loss: 0.6906 - val_accuracy: 0.5000\n",
      "Epoch 75/5000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6906 - accuracy: 0.5000 - val_loss: 0.6906 - val_accuracy: 0.5000\n",
      "Epoch 76/5000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6906 - accuracy: 0.5000 - val_loss: 0.6905 - val_accuracy: 0.5000\n",
      "Epoch 77/5000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6905 - accuracy: 0.5000 - val_loss: 0.6905 - val_accuracy: 0.5000\n",
      "Epoch 78/5000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6905 - accuracy: 0.5000 - val_loss: 0.6904 - val_accuracy: 0.5000\n",
      "Epoch 79/5000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6904 - accuracy: 0.5000 - val_loss: 0.6903 - val_accuracy: 0.5000\n",
      "Epoch 80/5000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6903 - accuracy: 0.5000 - val_loss: 0.6903 - val_accuracy: 0.5000\n",
      "Epoch 81/5000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6903 - accuracy: 0.5000 - val_loss: 0.6902 - val_accuracy: 0.5000\n",
      "Epoch 82/5000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6902 - accuracy: 0.5000 - val_loss: 0.6902 - val_accuracy: 0.5000\n",
      "Epoch 83/5000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6902 - accuracy: 0.5000 - val_loss: 0.6901 - val_accuracy: 0.5000\n",
      "Epoch 84/5000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6901 - accuracy: 0.5000 - val_loss: 0.6900 - val_accuracy: 0.5000\n",
      "Epoch 85/5000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6900 - accuracy: 0.5000 - val_loss: 0.6900 - val_accuracy: 0.5000\n",
      "Epoch 86/5000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6900 - accuracy: 0.5000 - val_loss: 0.6899 - val_accuracy: 0.5000\n",
      "Epoch 87/5000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6899 - accuracy: 0.5000 - val_loss: 0.6898 - val_accuracy: 0.5000\n",
      "Epoch 88/5000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6898 - accuracy: 0.5000 - val_loss: 0.6898 - val_accuracy: 0.5000\n",
      "Epoch 89/5000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6898 - accuracy: 0.5000 - val_loss: 0.6897 - val_accuracy: 0.5000\n",
      "Epoch 90/5000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6897 - accuracy: 0.5000 - val_loss: 0.6896 - val_accuracy: 0.5000\n",
      "Epoch 91/5000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6896 - accuracy: 0.5000 - val_loss: 0.6896 - val_accuracy: 0.5000\n",
      "Epoch 92/5000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6896 - accuracy: 0.5000 - val_loss: 0.6895 - val_accuracy: 0.5000\n",
      "Epoch 93/5000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6895 - accuracy: 0.5000 - val_loss: 0.6894 - val_accuracy: 0.5000\n",
      "Epoch 94/5000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6894 - accuracy: 0.5000 - val_loss: 0.6894 - val_accuracy: 0.5000\n",
      "Epoch 95/5000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6894 - accuracy: 0.5000 - val_loss: 0.6893 - val_accuracy: 0.5000\n",
      "Epoch 96/5000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6893 - accuracy: 0.5000 - val_loss: 0.6893 - val_accuracy: 0.5000\n",
      "Epoch 97/5000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6893 - accuracy: 0.5000 - val_loss: 0.6892 - val_accuracy: 0.5000\n",
      "Epoch 98/5000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6892 - accuracy: 0.5000 - val_loss: 0.6891 - val_accuracy: 0.5000\n",
      "Epoch 99/5000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6891 - accuracy: 0.5000 - val_loss: 0.6891 - val_accuracy: 0.5000\n",
      "Epoch 100/5000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6891 - accuracy: 0.5000 - val_loss: 0.6890 - val_accuracy: 0.5000\n",
      "Epoch 101/5000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6890 - accuracy: 0.5000 - val_loss: 0.6890 - val_accuracy: 0.5000\n",
      "Epoch 102/5000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6890 - accuracy: 0.5000 - val_loss: 0.6889 - val_accuracy: 0.5000\n",
      "Epoch 103/5000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6889 - accuracy: 0.5000 - val_loss: 0.6888 - val_accuracy: 0.5000\n",
      "Epoch 104/5000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6888 - accuracy: 0.5000 - val_loss: 0.6888 - val_accuracy: 0.5000\n",
      "Epoch 105/5000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6888 - accuracy: 0.5000 - val_loss: 0.6887 - val_accuracy: 0.5000\n",
      "Epoch 106/5000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6887 - accuracy: 0.5000 - val_loss: 0.6887 - val_accuracy: 0.5000\n",
      "Epoch 107/5000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6887 - accuracy: 0.5000 - val_loss: 0.6886 - val_accuracy: 0.5000\n",
      "Epoch 108/5000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6886 - accuracy: 0.5000 - val_loss: 0.6886 - val_accuracy: 0.5000\n",
      "Epoch 109/5000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6886 - accuracy: 0.5000 - val_loss: 0.6885 - val_accuracy: 0.5000\n",
      "Epoch 110/5000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6885 - accuracy: 0.5000 - val_loss: 0.6884 - val_accuracy: 0.5000\n",
      "Epoch 111/5000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6884 - accuracy: 0.5000 - val_loss: 0.6884 - val_accuracy: 0.5000\n",
      "Epoch 112/5000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6884 - accuracy: 0.5000 - val_loss: 0.6883 - val_accuracy: 0.5000\n",
      "Epoch 113/5000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6883 - accuracy: 0.5000 - val_loss: 0.6883 - val_accuracy: 0.5000\n",
      "Epoch 114/5000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6883 - accuracy: 0.5000 - val_loss: 0.6882 - val_accuracy: 0.5000\n",
      "Epoch 115/5000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6882 - accuracy: 0.5000 - val_loss: 0.6881 - val_accuracy: 0.5000\n",
      "Epoch 116/5000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6881 - accuracy: 0.5000 - val_loss: 0.6881 - val_accuracy: 0.5000\n",
      "Epoch 117/5000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6881 - accuracy: 0.5000 - val_loss: 0.6880 - val_accuracy: 0.5000\n",
      "Epoch 118/5000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6880 - accuracy: 0.5000 - val_loss: 0.6880 - val_accuracy: 0.5000\n",
      "Epoch 119/5000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6880 - accuracy: 0.5000 - val_loss: 0.6879 - val_accuracy: 0.5000\n",
      "Epoch 120/5000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6879 - accuracy: 0.5000 - val_loss: 0.6878 - val_accuracy: 0.5000\n",
      "Epoch 121/5000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6878 - accuracy: 0.5000 - val_loss: 0.6877 - val_accuracy: 0.5000\n",
      "Epoch 122/5000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6877 - accuracy: 0.5000 - val_loss: 0.6877 - val_accuracy: 0.5000\n",
      "Epoch 123/5000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6877 - accuracy: 0.5000 - val_loss: 0.6876 - val_accuracy: 0.5000\n",
      "Epoch 124/5000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6876 - accuracy: 0.5000 - val_loss: 0.6875 - val_accuracy: 0.5000\n",
      "Epoch 125/5000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6875 - accuracy: 0.5000 - val_loss: 0.6875 - val_accuracy: 0.5000\n",
      "Epoch 126/5000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6875 - accuracy: 0.5000 - val_loss: 0.6874 - val_accuracy: 0.5000\n",
      "Epoch 127/5000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6874 - accuracy: 0.5000 - val_loss: 0.6873 - val_accuracy: 0.5000\n",
      "Epoch 128/5000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6873 - accuracy: 0.5000 - val_loss: 0.6873 - val_accuracy: 0.5000\n",
      "Epoch 129/5000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6873 - accuracy: 0.5000 - val_loss: 0.6872 - val_accuracy: 0.5000\n",
      "Epoch 130/5000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6872 - accuracy: 0.5000 - val_loss: 0.6872 - val_accuracy: 0.5000\n",
      "Epoch 131/5000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6872 - accuracy: 0.5000 - val_loss: 0.6871 - val_accuracy: 0.5000\n",
      "Epoch 132/5000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6871 - accuracy: 0.5000 - val_loss: 0.6870 - val_accuracy: 0.5000\n",
      "Epoch 133/5000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6870 - accuracy: 0.5000 - val_loss: 0.6869 - val_accuracy: 0.5000\n",
      "Epoch 134/5000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6869 - accuracy: 0.5000 - val_loss: 0.6869 - val_accuracy: 0.5000\n",
      "Epoch 135/5000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6869 - accuracy: 0.5000 - val_loss: 0.6868 - val_accuracy: 0.5000\n",
      "Epoch 136/5000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6868 - accuracy: 0.5000 - val_loss: 0.6867 - val_accuracy: 0.5000\n",
      "Epoch 137/5000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6867 - accuracy: 0.5000 - val_loss: 0.6867 - val_accuracy: 0.5000\n",
      "Epoch 138/5000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6867 - accuracy: 0.5000 - val_loss: 0.6866 - val_accuracy: 0.5000\n",
      "Epoch 139/5000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6866 - accuracy: 0.5000 - val_loss: 0.6865 - val_accuracy: 0.5000\n",
      "Epoch 140/5000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6865 - accuracy: 0.5000 - val_loss: 0.6864 - val_accuracy: 0.5000\n",
      "Epoch 141/5000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6864 - accuracy: 0.5000 - val_loss: 0.6864 - val_accuracy: 0.5000\n",
      "Epoch 142/5000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6864 - accuracy: 0.5000 - val_loss: 0.6863 - val_accuracy: 0.5000\n",
      "Epoch 143/5000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6863 - accuracy: 0.5000 - val_loss: 0.6862 - val_accuracy: 0.5000\n",
      "Epoch 144/5000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6862 - accuracy: 0.5000 - val_loss: 0.6862 - val_accuracy: 0.5000\n",
      "Epoch 145/5000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6862 - accuracy: 0.5000 - val_loss: 0.6860 - val_accuracy: 0.5000\n",
      "Epoch 146/5000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6860 - accuracy: 0.5000 - val_loss: 0.6860 - val_accuracy: 0.5000\n",
      "Epoch 147/5000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6860 - accuracy: 0.5000 - val_loss: 0.6859 - val_accuracy: 0.5000\n",
      "Epoch 148/5000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6859 - accuracy: 0.5000 - val_loss: 0.6858 - val_accuracy: 0.5000\n",
      "Epoch 149/5000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6858 - accuracy: 0.5000 - val_loss: 0.6858 - val_accuracy: 0.5000\n",
      "Epoch 150/5000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6858 - accuracy: 0.5000 - val_loss: 0.6857 - val_accuracy: 0.5000\n",
      "Epoch 151/5000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6857 - accuracy: 0.5000 - val_loss: 0.6856 - val_accuracy: 0.5000\n",
      "Epoch 152/5000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6856 - accuracy: 0.5000 - val_loss: 0.6855 - val_accuracy: 0.5000\n",
      "Epoch 153/5000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6855 - accuracy: 0.5000 - val_loss: 0.6855 - val_accuracy: 0.5000\n",
      "Epoch 154/5000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6855 - accuracy: 0.5000 - val_loss: 0.6853 - val_accuracy: 0.5000\n",
      "Epoch 155/5000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6853 - accuracy: 0.5000 - val_loss: 0.6853 - val_accuracy: 0.5000\n",
      "Epoch 156/5000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6853 - accuracy: 0.5000 - val_loss: 0.6852 - val_accuracy: 0.5000\n",
      "Epoch 157/5000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6852 - accuracy: 0.5000 - val_loss: 0.6851 - val_accuracy: 0.5000\n",
      "Epoch 158/5000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6851 - accuracy: 0.5000 - val_loss: 0.6850 - val_accuracy: 0.5000\n",
      "Epoch 159/5000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6850 - accuracy: 0.5000 - val_loss: 0.6850 - val_accuracy: 0.5000\n",
      "Epoch 160/5000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6850 - accuracy: 0.5000 - val_loss: 0.6849 - val_accuracy: 0.5000\n",
      "Epoch 161/5000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6849 - accuracy: 0.5000 - val_loss: 0.6848 - val_accuracy: 0.5000\n",
      "Epoch 162/5000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6848 - accuracy: 0.5000 - val_loss: 0.6847 - val_accuracy: 0.5000\n",
      "Epoch 163/5000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6847 - accuracy: 0.5000 - val_loss: 0.6846 - val_accuracy: 0.5000\n",
      "Epoch 164/5000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6846 - accuracy: 0.5000 - val_loss: 0.6846 - val_accuracy: 0.5000\n",
      "Epoch 165/5000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6846 - accuracy: 0.5000 - val_loss: 0.6844 - val_accuracy: 0.5000\n",
      "Epoch 166/5000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6844 - accuracy: 0.5000 - val_loss: 0.6844 - val_accuracy: 0.5000\n",
      "Epoch 167/5000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6844 - accuracy: 0.5000 - val_loss: 0.6843 - val_accuracy: 0.5000\n",
      "Epoch 168/5000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6843 - accuracy: 0.5000 - val_loss: 0.6842 - val_accuracy: 0.5000\n",
      "Epoch 169/5000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6842 - accuracy: 0.5000 - val_loss: 0.6841 - val_accuracy: 0.5000\n",
      "Epoch 170/5000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6841 - accuracy: 0.5000 - val_loss: 0.6840 - val_accuracy: 0.5000\n",
      "Epoch 171/5000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6840 - accuracy: 0.5000 - val_loss: 0.6839 - val_accuracy: 0.5000\n",
      "Epoch 172/5000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6839 - accuracy: 0.5000 - val_loss: 0.6838 - val_accuracy: 0.5000\n",
      "Epoch 173/5000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6838 - accuracy: 0.5000 - val_loss: 0.6838 - val_accuracy: 0.5000\n",
      "Epoch 174/5000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6838 - accuracy: 0.5000 - val_loss: 0.6837 - val_accuracy: 0.5000\n",
      "Epoch 175/5000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6837 - accuracy: 0.5000 - val_loss: 0.6836 - val_accuracy: 0.5000\n",
      "Epoch 176/5000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6836 - accuracy: 0.5000 - val_loss: 0.6835 - val_accuracy: 0.5000\n",
      "Epoch 177/5000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6835 - accuracy: 0.5000 - val_loss: 0.6834 - val_accuracy: 0.5000\n",
      "Epoch 178/5000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6834 - accuracy: 0.5000 - val_loss: 0.6833 - val_accuracy: 0.5000\n",
      "Epoch 179/5000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6833 - accuracy: 0.5000 - val_loss: 0.6832 - val_accuracy: 0.5000\n",
      "Epoch 180/5000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6832 - accuracy: 0.5000 - val_loss: 0.6831 - val_accuracy: 0.5000\n",
      "Epoch 181/5000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6831 - accuracy: 0.5000 - val_loss: 0.6830 - val_accuracy: 0.5000\n",
      "Epoch 182/5000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6830 - accuracy: 0.5000 - val_loss: 0.6829 - val_accuracy: 0.5000\n",
      "Epoch 183/5000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6829 - accuracy: 0.5000 - val_loss: 0.6828 - val_accuracy: 0.5000\n",
      "Epoch 184/5000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6828 - accuracy: 0.5000 - val_loss: 0.6827 - val_accuracy: 0.5000\n",
      "Epoch 185/5000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6827 - accuracy: 0.5000 - val_loss: 0.6826 - val_accuracy: 0.5000\n",
      "Epoch 186/5000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6826 - accuracy: 0.5000 - val_loss: 0.6825 - val_accuracy: 0.5000\n",
      "Epoch 187/5000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6825 - accuracy: 0.5000 - val_loss: 0.6824 - val_accuracy: 0.5000\n",
      "Epoch 188/5000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6824 - accuracy: 0.5000 - val_loss: 0.6823 - val_accuracy: 0.5000\n",
      "Epoch 189/5000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6823 - accuracy: 0.5000 - val_loss: 0.6823 - val_accuracy: 0.5000\n",
      "Epoch 190/5000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6823 - accuracy: 0.5000 - val_loss: 0.6821 - val_accuracy: 0.5000\n",
      "Epoch 191/5000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6821 - accuracy: 0.5000 - val_loss: 0.6821 - val_accuracy: 0.5000\n",
      "Epoch 192/5000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6821 - accuracy: 0.5000 - val_loss: 0.6819 - val_accuracy: 0.5000\n",
      "Epoch 193/5000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6819 - accuracy: 0.5000 - val_loss: 0.6819 - val_accuracy: 0.5000\n",
      "Epoch 194/5000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6819 - accuracy: 0.5000 - val_loss: 0.6817 - val_accuracy: 0.5000\n",
      "Epoch 195/5000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6817 - accuracy: 0.5000 - val_loss: 0.6817 - val_accuracy: 0.5000\n",
      "Epoch 196/5000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6817 - accuracy: 0.5000 - val_loss: 0.6815 - val_accuracy: 0.5000\n",
      "Epoch 197/5000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6815 - accuracy: 0.5000 - val_loss: 0.6814 - val_accuracy: 0.5000\n",
      "Epoch 198/5000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6814 - accuracy: 0.5000 - val_loss: 0.6813 - val_accuracy: 0.5000\n",
      "Epoch 199/5000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6813 - accuracy: 0.5000 - val_loss: 0.6812 - val_accuracy: 0.5000\n",
      "Epoch 200/5000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6812 - accuracy: 0.5000 - val_loss: 0.6811 - val_accuracy: 0.5000\n",
      "Epoch 201/5000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6811 - accuracy: 0.5000 - val_loss: 0.6810 - val_accuracy: 0.5000\n",
      "Epoch 202/5000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6810 - accuracy: 0.5000 - val_loss: 0.6809 - val_accuracy: 0.5000\n",
      "Epoch 203/5000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6809 - accuracy: 0.5000 - val_loss: 0.6808 - val_accuracy: 0.5000\n",
      "Epoch 204/5000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6808 - accuracy: 0.5000 - val_loss: 0.6807 - val_accuracy: 0.5000\n",
      "Epoch 205/5000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6807 - accuracy: 0.5000 - val_loss: 0.6806 - val_accuracy: 0.5000\n",
      "Epoch 206/5000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6806 - accuracy: 0.5000 - val_loss: 0.6805 - val_accuracy: 0.5000\n",
      "Epoch 207/5000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6805 - accuracy: 0.5000 - val_loss: 0.6804 - val_accuracy: 0.5000\n",
      "Epoch 208/5000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6804 - accuracy: 0.5000 - val_loss: 0.6803 - val_accuracy: 0.5000\n",
      "Epoch 209/5000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6803 - accuracy: 0.5000 - val_loss: 0.6802 - val_accuracy: 0.5000\n",
      "Epoch 210/5000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6802 - accuracy: 0.5000 - val_loss: 0.6800 - val_accuracy: 0.5000\n",
      "Epoch 211/5000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6800 - accuracy: 0.5000 - val_loss: 0.6800 - val_accuracy: 0.5000\n",
      "Epoch 212/5000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6800 - accuracy: 0.5000 - val_loss: 0.6798 - val_accuracy: 0.5000\n",
      "Epoch 213/5000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6798 - accuracy: 0.5000 - val_loss: 0.6797 - val_accuracy: 0.5000\n",
      "Epoch 214/5000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6797 - accuracy: 0.5000 - val_loss: 0.6796 - val_accuracy: 0.5000\n",
      "Epoch 215/5000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6796 - accuracy: 0.5000 - val_loss: 0.6795 - val_accuracy: 0.5000\n",
      "Epoch 216/5000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6795 - accuracy: 0.5000 - val_loss: 0.6794 - val_accuracy: 0.5000\n",
      "Epoch 217/5000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6794 - accuracy: 0.5000 - val_loss: 0.6792 - val_accuracy: 0.5000\n",
      "Epoch 218/5000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6792 - accuracy: 0.5000 - val_loss: 0.6792 - val_accuracy: 0.5000\n",
      "Epoch 219/5000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6792 - accuracy: 0.5000 - val_loss: 0.6790 - val_accuracy: 0.5000\n",
      "Epoch 220/5000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6790 - accuracy: 0.5000 - val_loss: 0.6789 - val_accuracy: 0.5000\n",
      "Epoch 221/5000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6789 - accuracy: 0.5000 - val_loss: 0.6788 - val_accuracy: 0.5000\n",
      "Epoch 222/5000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6788 - accuracy: 0.5000 - val_loss: 0.6787 - val_accuracy: 0.5000\n",
      "Epoch 223/5000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6787 - accuracy: 0.5000 - val_loss: 0.6785 - val_accuracy: 0.5000\n",
      "Epoch 224/5000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6785 - accuracy: 0.5000 - val_loss: 0.6784 - val_accuracy: 0.5000\n",
      "Epoch 225/5000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6784 - accuracy: 0.5000 - val_loss: 0.6783 - val_accuracy: 0.5000\n",
      "Epoch 226/5000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6783 - accuracy: 0.5000 - val_loss: 0.6782 - val_accuracy: 0.5000\n",
      "Epoch 227/5000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6782 - accuracy: 0.5000 - val_loss: 0.6781 - val_accuracy: 0.5000\n",
      "Epoch 228/5000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6781 - accuracy: 0.5000 - val_loss: 0.6779 - val_accuracy: 0.5000\n",
      "Epoch 229/5000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6779 - accuracy: 0.5000 - val_loss: 0.6779 - val_accuracy: 0.5000\n",
      "Epoch 230/5000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6779 - accuracy: 0.5000 - val_loss: 0.6777 - val_accuracy: 0.5000\n",
      "Epoch 231/5000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6777 - accuracy: 0.5000 - val_loss: 0.6776 - val_accuracy: 0.5000\n",
      "Epoch 232/5000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6776 - accuracy: 0.5000 - val_loss: 0.6774 - val_accuracy: 0.5000\n",
      "Epoch 233/5000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6774 - accuracy: 0.5000 - val_loss: 0.6774 - val_accuracy: 0.5000\n",
      "Epoch 234/5000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6774 - accuracy: 0.5000 - val_loss: 0.6772 - val_accuracy: 0.5000\n",
      "Epoch 235/5000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6772 - accuracy: 0.5000 - val_loss: 0.6771 - val_accuracy: 0.5000\n",
      "Epoch 236/5000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6771 - accuracy: 0.5000 - val_loss: 0.6770 - val_accuracy: 0.5000\n",
      "Epoch 237/5000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6770 - accuracy: 0.5000 - val_loss: 0.6768 - val_accuracy: 0.5000\n",
      "Epoch 238/5000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6768 - accuracy: 0.5000 - val_loss: 0.6767 - val_accuracy: 0.5000\n",
      "Epoch 239/5000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6767 - accuracy: 0.5000 - val_loss: 0.6765 - val_accuracy: 0.5000\n",
      "Epoch 240/5000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6765 - accuracy: 0.5000 - val_loss: 0.6765 - val_accuracy: 0.5000\n",
      "Epoch 241/5000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6765 - accuracy: 0.5000 - val_loss: 0.6763 - val_accuracy: 0.5000\n",
      "Epoch 242/5000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6763 - accuracy: 0.5000 - val_loss: 0.6762 - val_accuracy: 0.5000\n",
      "Epoch 243/5000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6762 - accuracy: 0.5000 - val_loss: 0.6760 - val_accuracy: 0.5000\n",
      "Epoch 244/5000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6760 - accuracy: 0.5000 - val_loss: 0.6759 - val_accuracy: 0.5000\n",
      "Epoch 245/5000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6759 - accuracy: 0.5000 - val_loss: 0.6758 - val_accuracy: 0.5000\n",
      "Epoch 246/5000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6758 - accuracy: 0.5000 - val_loss: 0.6757 - val_accuracy: 0.5000\n",
      "Epoch 247/5000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6757 - accuracy: 0.5000 - val_loss: 0.6755 - val_accuracy: 0.5000\n",
      "Epoch 248/5000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6755 - accuracy: 0.5000 - val_loss: 0.6754 - val_accuracy: 0.5000\n",
      "Epoch 249/5000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6754 - accuracy: 0.5000 - val_loss: 0.6753 - val_accuracy: 0.5000\n",
      "Epoch 250/5000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6753 - accuracy: 0.5000 - val_loss: 0.6751 - val_accuracy: 0.5000\n",
      "Epoch 251/5000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6751 - accuracy: 0.5000 - val_loss: 0.6750 - val_accuracy: 0.5000\n",
      "Epoch 252/5000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6750 - accuracy: 0.5000 - val_loss: 0.6748 - val_accuracy: 0.5000\n",
      "Epoch 253/5000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6748 - accuracy: 0.5000 - val_loss: 0.6747 - val_accuracy: 0.5000\n",
      "Epoch 254/5000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6747 - accuracy: 0.5000 - val_loss: 0.6746 - val_accuracy: 0.5000\n",
      "Epoch 255/5000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6746 - accuracy: 0.5000 - val_loss: 0.6744 - val_accuracy: 0.5000\n",
      "Epoch 256/5000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6744 - accuracy: 0.5000 - val_loss: 0.6743 - val_accuracy: 0.5000\n",
      "Epoch 257/5000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6743 - accuracy: 0.5000 - val_loss: 0.6741 - val_accuracy: 0.5000\n",
      "Epoch 258/5000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6741 - accuracy: 0.5000 - val_loss: 0.6740 - val_accuracy: 0.5000\n",
      "Epoch 259/5000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6740 - accuracy: 0.5000 - val_loss: 0.6738 - val_accuracy: 0.5000\n",
      "Epoch 260/5000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6738 - accuracy: 0.5000 - val_loss: 0.6738 - val_accuracy: 0.5000\n",
      "Epoch 261/5000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6738 - accuracy: 0.5000 - val_loss: 0.6736 - val_accuracy: 0.5000\n",
      "Epoch 262/5000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6736 - accuracy: 0.5000 - val_loss: 0.6735 - val_accuracy: 0.5000\n",
      "Epoch 263/5000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6735 - accuracy: 0.5000 - val_loss: 0.6733 - val_accuracy: 0.5000\n",
      "Epoch 264/5000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6733 - accuracy: 0.5000 - val_loss: 0.6732 - val_accuracy: 0.5000\n",
      "Epoch 265/5000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6732 - accuracy: 0.5000 - val_loss: 0.6730 - val_accuracy: 0.5000\n",
      "Epoch 266/5000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6730 - accuracy: 0.5000 - val_loss: 0.6728 - val_accuracy: 0.5000\n",
      "Epoch 267/5000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6728 - accuracy: 0.5000 - val_loss: 0.6727 - val_accuracy: 0.5000\n",
      "Epoch 268/5000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6727 - accuracy: 0.5000 - val_loss: 0.6725 - val_accuracy: 0.5000\n",
      "Epoch 269/5000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6725 - accuracy: 0.5000 - val_loss: 0.6724 - val_accuracy: 0.5000\n",
      "Epoch 270/5000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6724 - accuracy: 0.5000 - val_loss: 0.6722 - val_accuracy: 0.5000\n",
      "Epoch 271/5000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6722 - accuracy: 0.5000 - val_loss: 0.6721 - val_accuracy: 0.5000\n",
      "Epoch 272/5000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6721 - accuracy: 0.5000 - val_loss: 0.6720 - val_accuracy: 0.5000\n",
      "Epoch 273/5000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6720 - accuracy: 0.5000 - val_loss: 0.6718 - val_accuracy: 0.5000\n",
      "Epoch 274/5000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6718 - accuracy: 0.5000 - val_loss: 0.6717 - val_accuracy: 0.5000\n",
      "Epoch 275/5000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6717 - accuracy: 0.5000 - val_loss: 0.6715 - val_accuracy: 0.5000\n",
      "Epoch 276/5000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6715 - accuracy: 0.5000 - val_loss: 0.6714 - val_accuracy: 0.5000\n",
      "Epoch 277/5000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6714 - accuracy: 0.5000 - val_loss: 0.6712 - val_accuracy: 0.5000\n",
      "Epoch 278/5000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6712 - accuracy: 0.5000 - val_loss: 0.6711 - val_accuracy: 0.5000\n",
      "Epoch 279/5000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6711 - accuracy: 0.5000 - val_loss: 0.6709 - val_accuracy: 0.5000\n",
      "Epoch 280/5000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6709 - accuracy: 0.5000 - val_loss: 0.6708 - val_accuracy: 0.5000\n",
      "Epoch 281/5000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6708 - accuracy: 0.5000 - val_loss: 0.6706 - val_accuracy: 0.5000\n",
      "Epoch 282/5000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6706 - accuracy: 0.5000 - val_loss: 0.6704 - val_accuracy: 0.5000\n",
      "Epoch 283/5000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6704 - accuracy: 0.5000 - val_loss: 0.6703 - val_accuracy: 0.5000\n",
      "Epoch 284/5000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6703 - accuracy: 0.5000 - val_loss: 0.6701 - val_accuracy: 0.5000\n",
      "Epoch 285/5000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6701 - accuracy: 0.5000 - val_loss: 0.6700 - val_accuracy: 0.5000\n",
      "Epoch 286/5000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6700 - accuracy: 0.5000 - val_loss: 0.6698 - val_accuracy: 0.5000\n",
      "Epoch 287/5000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6698 - accuracy: 0.5000 - val_loss: 0.6696 - val_accuracy: 0.5000\n",
      "Epoch 288/5000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6696 - accuracy: 0.5000 - val_loss: 0.6694 - val_accuracy: 0.5000\n",
      "Epoch 289/5000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6694 - accuracy: 0.5000 - val_loss: 0.6693 - val_accuracy: 0.5000\n",
      "Epoch 290/5000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6693 - accuracy: 0.5000 - val_loss: 0.6691 - val_accuracy: 0.5000\n",
      "Epoch 291/5000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6691 - accuracy: 0.5000 - val_loss: 0.6690 - val_accuracy: 0.5000\n",
      "Epoch 292/5000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6690 - accuracy: 0.5000 - val_loss: 0.6688 - val_accuracy: 0.5000\n",
      "Epoch 293/5000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6688 - accuracy: 0.5000 - val_loss: 0.6686 - val_accuracy: 0.5000\n",
      "Epoch 294/5000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6686 - accuracy: 0.5000 - val_loss: 0.6685 - val_accuracy: 0.5000\n",
      "Epoch 295/5000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6685 - accuracy: 0.5000 - val_loss: 0.6683 - val_accuracy: 0.5000\n",
      "Epoch 296/5000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6683 - accuracy: 0.5000 - val_loss: 0.6682 - val_accuracy: 0.5000\n",
      "Epoch 297/5000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6682 - accuracy: 0.5000 - val_loss: 0.6679 - val_accuracy: 0.5000\n",
      "Epoch 298/5000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6679 - accuracy: 0.5000 - val_loss: 0.6678 - val_accuracy: 0.5000\n",
      "Epoch 299/5000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6678 - accuracy: 0.5000 - val_loss: 0.6676 - val_accuracy: 0.5000\n",
      "Epoch 300/5000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6676 - accuracy: 0.5000 - val_loss: 0.6675 - val_accuracy: 0.5000\n",
      "Epoch 301/5000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6675 - accuracy: 0.5000 - val_loss: 0.6673 - val_accuracy: 0.5000\n",
      "Epoch 302/5000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6673 - accuracy: 0.5000 - val_loss: 0.6671 - val_accuracy: 0.5000\n",
      "Epoch 303/5000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6671 - accuracy: 0.5000 - val_loss: 0.6669 - val_accuracy: 0.5000\n",
      "Epoch 304/5000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6669 - accuracy: 0.5000 - val_loss: 0.6668 - val_accuracy: 0.5000\n",
      "Epoch 305/5000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6668 - accuracy: 0.5000 - val_loss: 0.6666 - val_accuracy: 0.5000\n",
      "Epoch 306/5000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6666 - accuracy: 0.5000 - val_loss: 0.6664 - val_accuracy: 0.5000\n",
      "Epoch 307/5000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6664 - accuracy: 0.5000 - val_loss: 0.6663 - val_accuracy: 0.5000\n",
      "Epoch 308/5000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6663 - accuracy: 0.5000 - val_loss: 0.6660 - val_accuracy: 0.5000\n",
      "Epoch 309/5000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6660 - accuracy: 0.5000 - val_loss: 0.6659 - val_accuracy: 0.5000\n",
      "Epoch 310/5000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6659 - accuracy: 0.5000 - val_loss: 0.6657 - val_accuracy: 0.5000\n",
      "Epoch 311/5000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6657 - accuracy: 0.5000 - val_loss: 0.6655 - val_accuracy: 0.5000\n",
      "Epoch 312/5000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6655 - accuracy: 0.5000 - val_loss: 0.6654 - val_accuracy: 0.5000\n",
      "Epoch 313/5000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6654 - accuracy: 0.5000 - val_loss: 0.6652 - val_accuracy: 0.5000\n",
      "Epoch 314/5000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6652 - accuracy: 0.5000 - val_loss: 0.6650 - val_accuracy: 0.5000\n",
      "Epoch 315/5000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6650 - accuracy: 0.5000 - val_loss: 0.6648 - val_accuracy: 0.5000\n",
      "Epoch 316/5000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6648 - accuracy: 0.5000 - val_loss: 0.6646 - val_accuracy: 0.5000\n",
      "Epoch 317/5000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6646 - accuracy: 0.5000 - val_loss: 0.6644 - val_accuracy: 0.5000\n",
      "Epoch 318/5000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6644 - accuracy: 0.5000 - val_loss: 0.6643 - val_accuracy: 0.5000\n",
      "Epoch 319/5000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6643 - accuracy: 0.5000 - val_loss: 0.6640 - val_accuracy: 0.5000\n",
      "Epoch 320/5000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6640 - accuracy: 0.5000 - val_loss: 0.6639 - val_accuracy: 0.5000\n",
      "Epoch 321/5000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6639 - accuracy: 0.5000 - val_loss: 0.6637 - val_accuracy: 0.5000\n",
      "Epoch 322/5000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6637 - accuracy: 0.5000 - val_loss: 0.6635 - val_accuracy: 0.5000\n",
      "Epoch 323/5000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6635 - accuracy: 0.5000 - val_loss: 0.6633 - val_accuracy: 0.5000\n",
      "Epoch 324/5000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6633 - accuracy: 0.5000 - val_loss: 0.6631 - val_accuracy: 0.5000\n",
      "Epoch 325/5000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6631 - accuracy: 0.5000 - val_loss: 0.6630 - val_accuracy: 0.5000\n",
      "Epoch 326/5000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6630 - accuracy: 0.5000 - val_loss: 0.6627 - val_accuracy: 0.5000\n",
      "Epoch 327/5000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6627 - accuracy: 0.5000 - val_loss: 0.6626 - val_accuracy: 0.5000\n",
      "Epoch 328/5000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6626 - accuracy: 0.5000 - val_loss: 0.6624 - val_accuracy: 0.5000\n",
      "Epoch 329/5000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6624 - accuracy: 0.5000 - val_loss: 0.6622 - val_accuracy: 0.5000\n",
      "Epoch 330/5000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6622 - accuracy: 0.5000 - val_loss: 0.6620 - val_accuracy: 0.5000\n",
      "Epoch 331/5000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6620 - accuracy: 0.5000 - val_loss: 0.6618 - val_accuracy: 0.5000\n",
      "Epoch 332/5000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6618 - accuracy: 0.5000 - val_loss: 0.6616 - val_accuracy: 0.5000\n",
      "Epoch 333/5000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6616 - accuracy: 0.5000 - val_loss: 0.6614 - val_accuracy: 0.5000\n",
      "Epoch 334/5000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6614 - accuracy: 0.5000 - val_loss: 0.6612 - val_accuracy: 0.5000\n",
      "Epoch 335/5000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6612 - accuracy: 0.5000 - val_loss: 0.6610 - val_accuracy: 0.5000\n",
      "Epoch 336/5000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6610 - accuracy: 0.5000 - val_loss: 0.6608 - val_accuracy: 0.5000\n",
      "Epoch 337/5000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6608 - accuracy: 0.5000 - val_loss: 0.6606 - val_accuracy: 0.5000\n",
      "Epoch 338/5000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6606 - accuracy: 0.5000 - val_loss: 0.6604 - val_accuracy: 0.5000\n",
      "Epoch 339/5000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6604 - accuracy: 0.5000 - val_loss: 0.6602 - val_accuracy: 0.7500\n",
      "Epoch 340/5000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6602 - accuracy: 0.7500 - val_loss: 0.6600 - val_accuracy: 0.7500\n",
      "Epoch 341/5000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6600 - accuracy: 0.7500 - val_loss: 0.6598 - val_accuracy: 0.7500\n",
      "Epoch 342/5000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6598 - accuracy: 0.7500 - val_loss: 0.6596 - val_accuracy: 0.7500\n",
      "Epoch 343/5000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6596 - accuracy: 0.7500 - val_loss: 0.6594 - val_accuracy: 0.7500\n",
      "Epoch 344/5000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6594 - accuracy: 0.7500 - val_loss: 0.6592 - val_accuracy: 0.7500\n",
      "Epoch 345/5000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6592 - accuracy: 0.7500 - val_loss: 0.6590 - val_accuracy: 0.7500\n",
      "Epoch 346/5000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6590 - accuracy: 0.7500 - val_loss: 0.6588 - val_accuracy: 0.7500\n",
      "Epoch 347/5000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6588 - accuracy: 0.7500 - val_loss: 0.6586 - val_accuracy: 0.7500\n",
      "Epoch 348/5000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6586 - accuracy: 0.7500 - val_loss: 0.6584 - val_accuracy: 0.7500\n",
      "Epoch 349/5000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6584 - accuracy: 0.7500 - val_loss: 0.6581 - val_accuracy: 0.7500\n",
      "Epoch 350/5000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6581 - accuracy: 0.7500 - val_loss: 0.6580 - val_accuracy: 0.7500\n",
      "Epoch 351/5000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6580 - accuracy: 0.7500 - val_loss: 0.6577 - val_accuracy: 0.7500\n",
      "Epoch 352/5000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6577 - accuracy: 0.7500 - val_loss: 0.6576 - val_accuracy: 0.7500\n",
      "Epoch 353/5000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6576 - accuracy: 0.7500 - val_loss: 0.6573 - val_accuracy: 0.7500\n",
      "Epoch 354/5000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6573 - accuracy: 0.7500 - val_loss: 0.6571 - val_accuracy: 0.7500\n",
      "Epoch 355/5000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6571 - accuracy: 0.7500 - val_loss: 0.6569 - val_accuracy: 0.7500\n",
      "Epoch 356/5000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6569 - accuracy: 0.7500 - val_loss: 0.6567 - val_accuracy: 0.7500\n",
      "Epoch 357/5000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6567 - accuracy: 0.7500 - val_loss: 0.6565 - val_accuracy: 0.7500\n",
      "Epoch 358/5000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6565 - accuracy: 0.7500 - val_loss: 0.6562 - val_accuracy: 0.7500\n",
      "Epoch 359/5000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6562 - accuracy: 0.7500 - val_loss: 0.6561 - val_accuracy: 0.7500\n",
      "Epoch 360/5000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6561 - accuracy: 0.7500 - val_loss: 0.6558 - val_accuracy: 0.7500\n",
      "Epoch 361/5000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6558 - accuracy: 0.7500 - val_loss: 0.6556 - val_accuracy: 0.7500\n",
      "Epoch 362/5000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6556 - accuracy: 0.7500 - val_loss: 0.6553 - val_accuracy: 0.7500\n",
      "Epoch 363/5000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6553 - accuracy: 0.7500 - val_loss: 0.6552 - val_accuracy: 0.7500\n",
      "Epoch 364/5000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6552 - accuracy: 0.7500 - val_loss: 0.6549 - val_accuracy: 0.7500\n",
      "Epoch 365/5000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6549 - accuracy: 0.7500 - val_loss: 0.6547 - val_accuracy: 0.7500\n",
      "Epoch 366/5000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6547 - accuracy: 0.7500 - val_loss: 0.6545 - val_accuracy: 0.7500\n",
      "Epoch 367/5000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6545 - accuracy: 0.7500 - val_loss: 0.6542 - val_accuracy: 0.7500\n",
      "Epoch 368/5000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6542 - accuracy: 0.7500 - val_loss: 0.6541 - val_accuracy: 0.7500\n",
      "Epoch 369/5000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6541 - accuracy: 0.7500 - val_loss: 0.6538 - val_accuracy: 0.7500\n",
      "Epoch 370/5000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6538 - accuracy: 0.7500 - val_loss: 0.6536 - val_accuracy: 0.7500\n",
      "Epoch 371/5000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6536 - accuracy: 0.7500 - val_loss: 0.6533 - val_accuracy: 0.7500\n",
      "Epoch 372/5000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6533 - accuracy: 0.7500 - val_loss: 0.6532 - val_accuracy: 0.7500\n",
      "Epoch 373/5000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6532 - accuracy: 0.7500 - val_loss: 0.6529 - val_accuracy: 0.7500\n",
      "Epoch 374/5000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6529 - accuracy: 0.7500 - val_loss: 0.6527 - val_accuracy: 0.7500\n",
      "Epoch 375/5000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6527 - accuracy: 0.7500 - val_loss: 0.6525 - val_accuracy: 0.7500\n",
      "Epoch 376/5000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6525 - accuracy: 0.7500 - val_loss: 0.6522 - val_accuracy: 0.7500\n",
      "Epoch 377/5000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6522 - accuracy: 0.7500 - val_loss: 0.6520 - val_accuracy: 0.7500\n",
      "Epoch 378/5000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6520 - accuracy: 0.7500 - val_loss: 0.6517 - val_accuracy: 0.7500\n",
      "Epoch 379/5000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6517 - accuracy: 0.7500 - val_loss: 0.6516 - val_accuracy: 0.7500\n",
      "Epoch 380/5000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6516 - accuracy: 0.7500 - val_loss: 0.6513 - val_accuracy: 0.7500\n",
      "Epoch 381/5000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6513 - accuracy: 0.7500 - val_loss: 0.6511 - val_accuracy: 0.7500\n",
      "Epoch 382/5000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6511 - accuracy: 0.7500 - val_loss: 0.6508 - val_accuracy: 0.7500\n",
      "Epoch 383/5000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6508 - accuracy: 0.7500 - val_loss: 0.6506 - val_accuracy: 0.7500\n",
      "Epoch 384/5000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6506 - accuracy: 0.7500 - val_loss: 0.6504 - val_accuracy: 0.7500\n",
      "Epoch 385/5000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6504 - accuracy: 0.7500 - val_loss: 0.6501 - val_accuracy: 0.7500\n",
      "Epoch 386/5000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6501 - accuracy: 0.7500 - val_loss: 0.6499 - val_accuracy: 0.7500\n",
      "Epoch 387/5000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6499 - accuracy: 0.7500 - val_loss: 0.6496 - val_accuracy: 0.7500\n",
      "Epoch 388/5000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6496 - accuracy: 0.7500 - val_loss: 0.6494 - val_accuracy: 0.7500\n",
      "Epoch 389/5000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6494 - accuracy: 0.7500 - val_loss: 0.6492 - val_accuracy: 0.7500\n",
      "Epoch 390/5000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6492 - accuracy: 0.7500 - val_loss: 0.6489 - val_accuracy: 0.7500\n",
      "Epoch 391/5000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6489 - accuracy: 0.7500 - val_loss: 0.6487 - val_accuracy: 0.7500\n",
      "Epoch 392/5000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6487 - accuracy: 0.7500 - val_loss: 0.6484 - val_accuracy: 0.7500\n",
      "Epoch 393/5000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6484 - accuracy: 0.7500 - val_loss: 0.6482 - val_accuracy: 0.7500\n",
      "Epoch 394/5000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6482 - accuracy: 0.7500 - val_loss: 0.6479 - val_accuracy: 0.7500\n",
      "Epoch 395/5000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6479 - accuracy: 0.7500 - val_loss: 0.6477 - val_accuracy: 0.7500\n",
      "Epoch 396/5000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6477 - accuracy: 0.7500 - val_loss: 0.6475 - val_accuracy: 0.7500\n",
      "Epoch 397/5000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6475 - accuracy: 0.7500 - val_loss: 0.6472 - val_accuracy: 0.7500\n",
      "Epoch 398/5000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6472 - accuracy: 0.7500 - val_loss: 0.6470 - val_accuracy: 0.7500\n",
      "Epoch 399/5000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6470 - accuracy: 0.7500 - val_loss: 0.6467 - val_accuracy: 0.7500\n",
      "Epoch 400/5000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6467 - accuracy: 0.7500 - val_loss: 0.6465 - val_accuracy: 0.7500\n",
      "Epoch 401/5000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6465 - accuracy: 0.7500 - val_loss: 0.6462 - val_accuracy: 0.7500\n",
      "Epoch 402/5000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6462 - accuracy: 0.7500 - val_loss: 0.6460 - val_accuracy: 0.7500\n",
      "Epoch 403/5000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6460 - accuracy: 0.7500 - val_loss: 0.6457 - val_accuracy: 0.7500\n",
      "Epoch 404/5000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6457 - accuracy: 0.7500 - val_loss: 0.6454 - val_accuracy: 0.7500\n",
      "Epoch 405/5000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6454 - accuracy: 0.7500 - val_loss: 0.6452 - val_accuracy: 0.7500\n",
      "Epoch 406/5000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6452 - accuracy: 0.7500 - val_loss: 0.6449 - val_accuracy: 0.7500\n",
      "Epoch 407/5000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6449 - accuracy: 0.7500 - val_loss: 0.6447 - val_accuracy: 0.7500\n",
      "Epoch 408/5000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6447 - accuracy: 0.7500 - val_loss: 0.6444 - val_accuracy: 0.7500\n",
      "Epoch 409/5000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6444 - accuracy: 0.7500 - val_loss: 0.6442 - val_accuracy: 0.7500\n",
      "Epoch 410/5000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6442 - accuracy: 0.7500 - val_loss: 0.6439 - val_accuracy: 0.7500\n",
      "Epoch 411/5000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6439 - accuracy: 0.7500 - val_loss: 0.6437 - val_accuracy: 0.7500\n",
      "Epoch 412/5000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6437 - accuracy: 0.7500 - val_loss: 0.6434 - val_accuracy: 0.7500\n",
      "Epoch 413/5000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6434 - accuracy: 0.7500 - val_loss: 0.6431 - val_accuracy: 0.7500\n",
      "Epoch 414/5000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6431 - accuracy: 0.7500 - val_loss: 0.6429 - val_accuracy: 0.7500\n",
      "Epoch 415/5000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6429 - accuracy: 0.7500 - val_loss: 0.6426 - val_accuracy: 0.7500\n",
      "Epoch 416/5000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6426 - accuracy: 0.7500 - val_loss: 0.6424 - val_accuracy: 0.7500\n",
      "Epoch 417/5000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6424 - accuracy: 0.7500 - val_loss: 0.6421 - val_accuracy: 0.7500\n",
      "Epoch 418/5000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6421 - accuracy: 0.7500 - val_loss: 0.6418 - val_accuracy: 0.7500\n",
      "Epoch 419/5000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6418 - accuracy: 0.7500 - val_loss: 0.6416 - val_accuracy: 0.7500\n",
      "Epoch 420/5000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6416 - accuracy: 0.7500 - val_loss: 0.6413 - val_accuracy: 0.7500\n",
      "Epoch 421/5000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6413 - accuracy: 0.7500 - val_loss: 0.6411 - val_accuracy: 0.7500\n",
      "Epoch 422/5000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6411 - accuracy: 0.7500 - val_loss: 0.6408 - val_accuracy: 0.7500\n",
      "Epoch 423/5000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6408 - accuracy: 0.7500 - val_loss: 0.6405 - val_accuracy: 1.0000\n",
      "\n",
      "Reached 100% accuracy, stopping training\n"
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "# tf.random.set_seed(17)\n",
    "history = model.fit(\n",
    "        x, y,\n",
    "        epochs = 5000,\n",
    "        validation_data = (x, y),\n",
    "        callbacks = [callbacks]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 874,
     "status": "ok",
     "timestamp": 1620282436051,
     "user": {
      "displayName": "Ramesh Bhutka",
      "photoUrl": "https://lh3.googleusercontent.com/-jBSHGVJvh3M/AAAAAAAAAAI/AAAAAAAAchY/NveHJuhGTqU/s64/photo.jpg",
      "userId": "06756766942721289592"
     },
     "user_tz": -330
    },
    "id": "6o5r6xM2o4s7",
    "outputId": "a583fd35-2a22-41bc-9213-06f1fe7727e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6405 - accuracy: 1.0000\n",
      "Loss : 0.640494167804718\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6405 - accuracy: 1.0000\n",
      "Accuracy % : 100.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loss : {model.evaluate(x,y)[0]}\")\n",
    "print(f\"Accuracy % : {model.evaluate(x,y)[1]*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1258,
     "status": "ok",
     "timestamp": 1620282439987,
     "user": {
      "displayName": "Ramesh Bhutka",
      "photoUrl": "https://lh3.googleusercontent.com/-jBSHGVJvh3M/AAAAAAAAAAI/AAAAAAAAchY/NveHJuhGTqU/s64/photo.jpg",
      "userId": "06756766942721289592"
     },
     "user_tz": -330
    },
    "id": "J7ySZygVpR7a",
    "outputId": "318469cd-1a0f-4bee-ffdf-8c0cfab91389"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[2 0]\n",
      " [0 2]]\n",
      "Accuracy Score: 100.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict_classes(x)\n",
    "predictions = predictions.reshape(1,-1)[0]\n",
    "\n",
    "# confusion matrix\n",
    "print('Confusion Matrix:\\n', confusion_matrix(y, predictions), sep='')\n",
    "print(f'Accuracy Score: {accuracy_score(y, predictions)*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2974,
     "status": "ok",
     "timestamp": 1620282444827,
     "user": {
      "displayName": "Ramesh Bhutka",
      "photoUrl": "https://lh3.googleusercontent.com/-jBSHGVJvh3M/AAAAAAAAAAI/AAAAAAAAchY/NveHJuhGTqU/s64/photo.jpg",
      "userId": "06756766942721289592"
     },
     "user_tz": -330
    },
    "id": "AehnAzEVpTvp",
    "outputId": "4655fffd-4de2-4e5e-9f9e-fe6d49a93975"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0]\t\t0\n",
      "[0 1]\t\t1\n",
      "[1 0]\t\t1\n",
      "[1 1]\t\t0\n"
     ]
    }
   ],
   "source": [
    "# verifying outputs manually\n",
    "for i in range(len(x)):\n",
    "    print(f'{x[i]}\\t\\t{predictions[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "executionInfo": {
     "elapsed": 3454,
     "status": "ok",
     "timestamp": 1620282466638,
     "user": {
      "displayName": "Ramesh Bhutka",
      "photoUrl": "https://lh3.googleusercontent.com/-jBSHGVJvh3M/AAAAAAAAAAI/AAAAAAAAchY/NveHJuhGTqU/s64/photo.jpg",
      "userId": "06756766942721289592"
     },
     "user_tz": -330
    },
    "id": "ytMF6OSapVlp",
    "outputId": "30120b02-aff8-42cb-a699-c708f6748705"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train and validation accuracy trends\n",
    "train_accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "epochs = [i for i in range(0, 423)]\n",
    "plt.plot(epochs, train_accuracy, 'r', label='Train Accuracy')\n",
    "plt.plot(epochs, val_accuracy, 'g', label='Validation Accuracy')\n",
    "plt.title('Train vs Validation Accuracy Trends')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "executionInfo": {
     "elapsed": 6071,
     "status": "ok",
     "timestamp": 1620282477809,
     "user": {
      "displayName": "Ramesh Bhutka",
      "photoUrl": "https://lh3.googleusercontent.com/-jBSHGVJvh3M/AAAAAAAAAAI/AAAAAAAAchY/NveHJuhGTqU/s64/photo.jpg",
      "userId": "06756766942721289592"
     },
     "user_tz": -330
    },
    "id": "n7lDUQwHpXzq",
    "outputId": "a5455121-a47f-4bb5-f62e-798e3c6115aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Detected Colab notebook...\u001b[0m\n",
      "[jovian] Uploading colab notebook to Jovian...\u001b[0m\n",
      "[jovian] Capturing environment..\u001b[0m\n",
      "[jovian] Committed successfully! https://jovian.ai/rameshbhutka11/practical-5-x-or-problem\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'https://jovian.ai/rameshbhutka11/practical-5-x-or-problem'"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jovian.commit(project=\"practical-5-x-or-problem\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Epx1l3S4qqwM"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "practical-5-x-or-problem.ipynb",
   "provenance": []
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}